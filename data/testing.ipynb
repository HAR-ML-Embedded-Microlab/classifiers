{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting CSV files...\n",
      "Processing windows...\n",
      "Relabelling data...\n",
      "Saving data...\n",
      "Generating class weights...\n",
      "Shuffling dataset...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'work/train_windows_tmp.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 164\u001b[0m\n\u001b[0;32m    161\u001b[0m     test_windows_shuffled[i] \u001b[39m=\u001b[39m test_windows[test_shuffle[i]]\n\u001b[0;32m    162\u001b[0m     test_labels_shuffled[i] \u001b[39m=\u001b[39m test_labels[test_shuffle[i]]\n\u001b[1;32m--> 164\u001b[0m os\u001b[39m.\u001b[39;49mremove(\u001b[39m'\u001b[39;49m\u001b[39mwork/train_windows_tmp.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    165\u001b[0m os\u001b[39m.\u001b[39mremove(\u001b[39m'\u001b[39m\u001b[39mwork/train_labels_tmp.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    166\u001b[0m os\u001b[39m.\u001b[39mremove(\u001b[39m'\u001b[39m\u001b[39mwork/test_windows_tmp.npy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'work/train_windows_tmp.npy'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from numpy.lib.format import open_memmap\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "num_samples = 50\n",
    "\n",
    "harth_filenames = [\n",
    "    './harth-ml-experiments/harth/S006.csv',\n",
    "    './harth-ml-experiments/harth/S008.csv',\n",
    "    './harth-ml-experiments/harth/S009.csv',\n",
    "    './harth-ml-experiments/harth/S010.csv',\n",
    "    './harth-ml-experiments/harth/S012.csv',\n",
    "    './harth-ml-experiments/harth/S013.csv',\n",
    "    './harth-ml-experiments/harth/S014.csv',\n",
    "    './harth-ml-experiments/harth/S015.csv',\n",
    "    './harth-ml-experiments/harth/S016.csv',\n",
    "    './harth-ml-experiments/harth/S017.csv',\n",
    "    './harth-ml-experiments/harth/S018.csv',\n",
    "    './harth-ml-experiments/harth/S019.csv',\n",
    "    './harth-ml-experiments/harth/S020.csv',\n",
    "    './harth-ml-experiments/harth/S021.csv',\n",
    "    './harth-ml-experiments/harth/S022.csv',\n",
    "    './harth-ml-experiments/harth/S023.csv',\n",
    "    './harth-ml-experiments/harth/S024.csv',\n",
    "    './harth-ml-experiments/harth/S025.csv',\n",
    "    './harth-ml-experiments/harth/S026.csv',\n",
    "    './harth-ml-experiments/harth/S027.csv',\n",
    "    './harth-ml-experiments/harth/S028.csv',\n",
    "    './harth-ml-experiments/harth/S029.csv',\n",
    "    './harth-ml-experiments/har70plus/501.csv',\n",
    "    './harth-ml-experiments/har70plus/502.csv',\n",
    "    './harth-ml-experiments/har70plus/503.csv',\n",
    "    './harth-ml-experiments/har70plus/504.csv',\n",
    "    './harth-ml-experiments/har70plus/505.csv',\n",
    "    './harth-ml-experiments/har70plus/506.csv',\n",
    "    './harth-ml-experiments/har70plus/507.csv',\n",
    "    './harth-ml-experiments/har70plus/508.csv',\n",
    "    './harth-ml-experiments/har70plus/509.csv',\n",
    "    './harth-ml-experiments/har70plus/510.csv',\n",
    "    './harth-ml-experiments/har70plus/511.csv',\n",
    "    './harth-ml-experiments/har70plus/512.csv',\n",
    "    './harth-ml-experiments/har70plus/513.csv',\n",
    "    './harth-ml-experiments/har70plus/514.csv',\n",
    "    './harth-ml-experiments/har70plus/515.csv',\n",
    "    './harth-ml-experiments/har70plus/516.csv',\n",
    "    './harth-ml-experiments/har70plus/517.csv',\n",
    "    './harth-ml-experiments/har70plus/518.csv'\n",
    "]\n",
    "\n",
    "permanent_shuffling = [19, 12] #, 14, 15, 1, 10, 4, 18, 5, 20, 21, 6, 11, 16, 13, 9, 7, 17, 38, 29, 33, 27, 37, 26, 40, 35, 31, 32, 25, 23, 28, 34, 2, 3, 8, 22, 24, 30, 36, 39]\n",
    "\n",
    "# harth_filenames = [harth_filenames[i-1] for i in permanent_shuffling]\n",
    "train_test_split = 1 # int(0.8 * len(harth_filenames))\n",
    "\n",
    "num_windows_train = 0\n",
    "num_windows_test = 0\n",
    "\n",
    "print(\"Ingesting CSV files...\")\n",
    "\n",
    "data_nps = [None] * len(permanent_shuffling)\n",
    "for i in range(len(permanent_shuffling)):\n",
    "    data_df = pd.read_csv(harth_filenames[i])\n",
    "    data_df.drop(['timestamp'], axis=1, inplace=True)\n",
    "    data_df.drop(['index'], axis=1, errors='ignore', inplace=True)\n",
    "    data_df.drop([''], axis=1, errors='ignore', inplace=True)\n",
    "    data_df.drop([' '], axis=1, errors='ignore', inplace=True)\n",
    "    data_df.rename({\"Unnamed: 0\":\"a\"}, errors='ignore', axis=\"columns\", inplace=True)\n",
    "    data_df.drop(['a'], axis=1, errors='ignore', inplace=True)\n",
    "    data_df.dropna(inplace=True)\n",
    "    data_nps[i] = data_df.to_numpy(dtype=np.float32)\n",
    "    if permanent_shuffling[i]==1:\n",
    "        data_nps[i]=data_nps[i][::2]\n",
    "    if i < train_test_split:\n",
    "        num_windows_train += data_nps[i].shape[0] - num_samples + 1\n",
    "    else:\n",
    "        num_windows_test += data_nps[i].shape[0] - num_samples + 1\n",
    "    del data_df # memory is scarce after all\n",
    "    \n",
    "print(\"Processing windows...\")\n",
    "\n",
    "train_windows = open_memmap('work/train_windows_tmp.npy', mode='w+', dtype=np.float32, shape=(num_windows_train, 6, num_samples))\n",
    "train_labels = open_memmap('work/train_labels_tmp.npy', mode='w+', dtype=np.int32, shape=(num_windows_train,))\n",
    "test_windows = open_memmap('work/test_windows_tmp.npy', mode='w+', dtype=np.float32, shape=(num_windows_test, 6, num_samples))\n",
    "test_labels = open_memmap('work/test_labels_tmp.npy', mode='w+', dtype=np.int32, shape=(num_windows_test,))\n",
    "\n",
    "num_windows_train_processed = 0\n",
    "num_windows_test_processed = 0\n",
    "\n",
    "for i in range(len(permanent_shuffling)):\n",
    "    # Since the sensors have been set to +-8G, divide by 8 to scale to 0~1 range.\n",
    "    if i < train_test_split:\n",
    "        train_windows[num_windows_train_processed:num_windows_train_processed+data_nps[i].shape[0] - num_samples + 1] = sliding_window_view(data_nps[i][:,0:6], window_shape=num_samples, axis=0)/np.float32(8)\n",
    "        train_labels[num_windows_train_processed:num_windows_train_processed+data_nps[i].shape[0] - num_samples + 1] = sp.stats.mode(sliding_window_view(data_nps[i][:,6], window_shape=num_samples), keepdims=False, axis=1)[0].astype(np.int32)\n",
    "        num_windows_train_processed += data_nps[i].shape[0] - num_samples + 1\n",
    "    else:\n",
    "        test_windows[num_windows_test_processed:num_windows_test_processed+data_nps[i].shape[0] - num_samples + 1] = sliding_window_view(data_nps[i][:,0:6], window_shape=num_samples, axis=0)/np.float32(8)\n",
    "        test_labels[num_windows_test_processed:num_windows_test_processed+data_nps[i].shape[0] - num_samples + 1] = sp.stats.mode(sliding_window_view(data_nps[i][:,6], window_shape=num_samples), keepdims=False, axis=1)[0].astype(np.int32)\n",
    "        num_windows_test_processed += data_nps[i].shape[0] - num_samples + 1\n",
    "\n",
    "del data_nps[:]\n",
    "del data_nps\n",
    "\n",
    "print(\"Relabelling data...\")\n",
    "\n",
    "train_labels[train_labels==13] = 9\n",
    "train_labels[train_labels==14] = 10\n",
    "train_labels[train_labels==130] = 11\n",
    "train_labels[train_labels==140] = 12\n",
    "train_labels[:] = train_labels-1\n",
    "\n",
    "test_labels[test_labels==13] = 9\n",
    "test_labels[test_labels==14] = 10\n",
    "test_labels[test_labels==130] = 11\n",
    "test_labels[test_labels==140] = 12\n",
    "test_labels[:] = test_labels-1\n",
    "\n",
    "print(\"Saving data...\")\n",
    "\n",
    "train_labels.flush()\n",
    "train_windows.flush()\n",
    "test_labels.flush()\n",
    "test_windows.flush()\n",
    "\n",
    "print(\"Generating class weights...\")\n",
    "\n",
    "# Use sklearn.utils.class_weight.compute_class_weight's algorithm without importing sklearn.\n",
    "# num_classes = 12\n",
    "# weights = train_labels.size/(num_classes*np.bincount(train_labels))\n",
    "# class_weights = {i:weights[i] for i in range(num_classes)}\n",
    "\n",
    "# with open(\"work/class_weights.json\", \"w\") as jsonfile:\n",
    "#     json.dump(class_weights, jsonfile, indent=4)   \n",
    "    \n",
    "print(\"Shuffling dataset...\")\n",
    "\n",
    "train_windows_shuffled = open_memmap('work/train_windows.npy', mode='w+', dtype=np.float32, shape=(num_windows_train, 6, 50))\n",
    "train_labels_shuffled = open_memmap('work/train_labels.npy', mode='w+', dtype=np.int32, shape=(num_windows_train,12))\n",
    "test_windows_shuffled = open_memmap('work/test_windows.npy', mode='w+', dtype=np.float32, shape=(num_windows_test, 6, 50))\n",
    "test_labels_shuffled = open_memmap('work/test_labels.npy', mode='w+', dtype=np.int32, shape=(num_windows_test,12))\n",
    "\n",
    "train_shuffle = np.arange(train_labels.size)\n",
    "test_shuffle = np.arange(test_labels.size)\n",
    "np.random.shuffle(train_shuffle)\n",
    "np.random.shuffle(test_shuffle)\n",
    "\n",
    "for i in range(train_labels.size):\n",
    "    train_windows_shuffled[i] = train_windows[train_shuffle[i]]\n",
    "    train_labels_shuffled[i] = train_labels[train_shuffle[i]]\n",
    "    \n",
    "for i in range(test_labels.size):\n",
    "    test_windows_shuffled[i] = test_windows[test_shuffle[i]]\n",
    "    test_labels_shuffled[i] = test_labels[test_shuffle[i]]\n",
    "\n",
    "print(train_labels_shuffled)\n",
    "\n",
    "print(\"One-Hot encoding...\")\n",
    "\n",
    "train_labels_shuffled[:] = np.array([to_categorical(train_labels_shuffled[i][0], num_classes=12) for i in range(len(train_labels_shuffled))], dtype=np.int32)\n",
    "test_labels_shuffled[:] = np.array([to_categorical(test_labels_shuffled[i][0], num_classes=12) for i in range(len(test_labels_shuffled))], dtype=np.int32)\n",
    "\n",
    "print(train_labels_shuffled)\n",
    "\n",
    "print(\"Flush...\")\n",
    "\n",
    "train_windows_shuffled.flush()\n",
    "train_labels_shuffled.flush()\n",
    "test_windows_shuffled.flush()\n",
    "test_labels_shuffled.flush()\n",
    "\n",
    "os.remove('work/train_windows_tmp.npy')\n",
    "os.remove('work/train_labels_tmp.npy')\n",
    "os.remove('work/test_windows_tmp.npy')\n",
    "os.remove('work/test_labels_tmp.npy')\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
